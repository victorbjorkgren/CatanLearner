import torch as T

# ENVIRONMENT AND DISPLAY
MAX_STEPS = 100_000_000
HISTORY_DISPLAY = 100
MAX_TURNS = 800
N_PLAYERS = 1
LATENT_REWARD = .01

# LEARNER
BATCH_SIZE = 16
LEARNING_RATE = 3e-4
REWARD_SCALE = 1.
GAMMA = .999
LOSS_CLIP = .6
GRAD_CLIP = .5
SAVE_LATEST_NET_INTERVAL  = 1
SAVE_CHECKPOINT_NET_INTERVAL = 1000

# ACTORS
USE_ACTOR_PRIO = True
FAILURE_ALLOWANCE = 2
EPS_MIN = .9
EPS_MAX = .99
EPS_ZERO = .5  # Chance that epsilon becomes zero
EPS_ONE = .1  # Chance that epsilon becomes one

# NETWORK
N_POWER_LAYERS = 3
N_HIDDEN_NODES = 32
MAX_SEQUENCE_LENGTH = 2000
BURN_IN_LENGTH = 20  # TODO: NOT USED, USE.
DENSE_FORWARD = False

# PPO
PPO_VALUE_COEF = .5
PPO_ENTROPY_COEF = .0025

#
SAC_ENTROPY_ALPHA = .002
SAC_TARGET_TAU = .01

# REPLAY
REPLAY_MEMORY_SIZE = BATCH_SIZE * 4
REPLAY_ALPHA = .7
REPLAY_BETA = .8

LOAD_Q_NET = True
LOAD_BUFFER = True

# LEARNER_DEVICE = 'mps' if T.backends.mps.is_available() else 'cpu'
LEARNER_DEVICE = 'cpu'
ACTOR_DEVICE = 'cpu'
